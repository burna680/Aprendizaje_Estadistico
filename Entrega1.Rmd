---
title: "Entrega1"
output: html_document
date: '2022-05-26'
editor_options: 
  chunk_output_type: inline
  fig_width: 6 
  fig_height: 4 
---

```{r setup, include=FALSE, results=FALSE}
knitr::opts_chunk$set(echo = FALSE, results = FALSE, warning=FALSE, message=FALSE, fig.align = "center", fig.width=12, fig.height=8)
```

```{r pressure}
library(ggplot2)
library(GGally)
library(dplyr) #For filter usage
library(gridExtra) #For subplots with ggplot
library(hrbrthemes)
library(latex2exp)
library(leaps)
source("functions.R")
library(bestglm)
```

Todos los pacientes son de sexo femenino mayores de 21 años de herencia Pima. Para este primer estudio, lo que buscaremos es encontrar relaciones entre otras de las variables contenidas en el dataset.

## Punto 1

```{r}
if(Sys.info()[['sysname']] == "Windows"){
  setwd("g:\\LUCAS\\Facultad\\Aprendizaje Estadistico\\Entregas\\Primera\\")
} else {
  setwd("~/Desktop/Facultad/Aprendizaje_estadistico/TP1")
}
  

data<-read.csv("diabetes2.csv",header=T,sep=",")
data$Outcome<-as.factor(data$Outcome)
```

Se analizaron los datos y se llega a la conclusión de que todas las columnas se encuentran bien definidas.

La columna X parecería ser un contador ya que es siempre ascendiente aunque faltan algunos numeros, podría ser un identificador de muestras. Por lo tanto no lo tomamos en cuenta para los análisis siguientes.

```{r}
data = within(data, rm(X))
```

Revisando los valores se nota que algunas filas tienen algunos valores en 0 que no tendrían mucho sentido en este contexto medicinal. Por ejemplo no se le encuentra mucho sentido que la presión sanguínea sea 0. Por lo tanto se comienza una exploración de datos para ver que porcentaje de los datos tienen valores en 0. Igualmente este análisis se deja para el punto 10 de selección de modelos.\
\

## **Punto 2**

El modelo resulta

$\Omega$: Y= X$\beta$+$\epsilon$

Cuyos supuestos son:

1.  Y $\sim$ $\mathcal{N}$(X$\beta$, $\sigma^2I$) , los valores de BMI

    Y $\in$ $\mathcal{R} ^{nx1}, n=539$ la cantidad de observaciones

2.  E($\epsilon$)=0 , $\epsilon\in$ $\mathcal{R} ^{nx1}$

3.  Var($\epsilon$)= $\sigma^2$

4.  $Y_{1}, \ldots, Y_{n}$ son independientes

    Al definir los elementos\
    $$
    Y=\left(y_{1}, \ldots, y_{n}\right)^{T}, \epsilon=\left(\epsilon_{1}, \ldots, \epsilon_{n}\right)^{T}, \beta=\left(\beta_{1}, \ldots, \beta_{p}\right)^{T}
    $$

    $\beta\in$ $\mathcal{R} ^{px1}$

    X $\in$ $\mathcal{R} ^{nxp}, p= 8$ Es la matriz de diseño. La cantidad de variables del modelo es p. Incluyen la cantidad de embarazos, el nivel de glucosa, etc. $$\mathbf{X}=\left[\begin{array}{cccc}1 & x_{11} & \ldots & x_{1(p-1)} \\1 & \cdot & \cdot & \cdot \\1 & \cdot & \cdot & \cdot \\1 & \cdot & \cdot & \cdot \\1 & x_{n 1} & \ldots & x_{n(p-1)}\end{array}\right]$$

Cuál es el modelo propuesto? verificar los puntos de BMI con qqnorm

## Punto 3

La siguiente tabla muestra las correlaciones entre los distintos pares de variables del dataset. Se puede ver que en la última columna no se muestran los resultados como en las otras ya que la variable Outcome es una variable categórica.

```{r}
ggpairs(data)
```

## Punto 4

Al ver la tabla podemos ver que existe una mayor correlación entre los valores de la SkinThickness y los de BMI, por lo que si tuviéramos que perder información eligiendo sólo una variable de las contenidas en el dataset sería la SkinThickness ya que sería un modelo de regresión lineal simple y la correlación da una noción de como explica una variable a la otra.

## Punto 5

```{r, results = TRUE}
vars = cbind(Glucose = data$Glucose, Pregnancies = data$Pregnancies, BloodPressure = data$BloodPressure, SkinThickness = data$SkinThickness, Insulin = data$Insulin, DiabetesPedigreeFunction = data$DiabetesPedigreeFunction, Age = data$Age)

lin_reg = lm(data$BMI~vars, data = data)
summary(lin_reg)
```

En la anterior tabla se puede ver el resultado de la regresión lineal múltiple.

En la parte de coeficientes cada fila expresa medidas de cada coeficiente de los parámetros estimados ($\beta_i$). La primer columna es el valor de la estimación, y después las otras tres columnas son tests de hipótesis para cada estimación de la siguiente forma:

$$
H_{0}: \beta_{i}=0 \quad V s . \quad H_{1}: \beta_{i} \neq 0
$$

La regla de decisión será

$$
\varphi(\underline{X})= \begin{cases}1 & \text { si } \quad|T|>k_{\alpha} \\ 0 & \text { en otro caso }\end{cases}
$$

Donde

$$
T=\frac{\hat{\beta_i}}{S \sqrt{d_{i i}}}, T ∼ t_{n - p}
$$

Donde S es la estimación (insesgada) del desvío estándar del estimador.

Y $d_{ii}$ es el elemento de la matriz $D=\left(\mathbf{X}^{T} \mathbf{X}\right)^{-1}$

$k_{\alpha}$ es una constante que depende de $\alpha$ que es el nivel de significación del test.

Por último el p-valor se calcula de la siguiente manera:

$$
p-\text { valor }=2 \mathbf{P}\left(T \geq\left|T_{o b s}\right|\right)
$$

Entonces la columna de Std. Error es la multiplicación de $s$ y $\sqrt{d_{ii}}$, t value es el valor obtenido del estadístico T, osea: $\frac{\hat{\beta_i}}{s \sqrt{d_{i i}}}$

Y la última columna es el p valor obtenido para ese $t$, osea: $2 \mathbf{P}\left(T \geq\left|t\right|\right)$

Como ejemplo se toma la variable SkinThickness y se calcula a "mano" los valores:

$$S^{2}=\frac{\|Y-\hat{Y}\|^{2}}{n-p}$$

```{r, results=TRUE, echo=TRUE}
Y_hat = predict(lin_reg)
s = sqrt(norm(as.matrix(data$BMI - Y_hat), type = "2")**2 / (539 - 8))
s
```

Que es el mismo que aparece en la tabla como Residual Standar Error.

```{r, results=TRUE, echo=TRUE}
X = cbind(rep(c(1), 539), vars) # vars contiene las columnas en el orden igual al que se hizo la regresion lineal
D = solve(t(X) %*% X)
d44 = D[5, 5] # ya que el 0,0 sería el del intercept
std_err_b4 = (sqrt(d44) * s)
std_err_b4
```

Que es el mismo valor que se obtiene en la tabla como Std. Error.

```{r, results=TRUE, echo=TRUE}
t_b4 = unname(lin_reg$coefficients['varsSkinThickness']/std_err_b4)
t_b4
```

Que es el valor que se obtiene de la tabla como t value

Por último se puede calcular el p valor usando la función de distribución de la t de Student

```{r, results=TRUE, echo=TRUE}
2*(1 - pt(t_b4, 539 - 8))
```

Ahora mirando todos los resultados se puede decidir que valores son significativos de la estimación y se decide que las variables con un valor significativo ($p-valor < 0.05$) del test son:

-   Intercept ($\beta_0$)

-   BloodPressure

-   SkinThickness

-   Insulin

-   DiabetesPedigreeFunction

## Punto 6

$$
R^{2}=\frac{\|\hat{Y}-\bar{Y}\|^{2}}{\|Y-\bar{Y}\|^{2}}=\frac{S C R}{S C T}= 0.4669
$$

Donde $\hat Y$ es la estimación de $Y$ e $\bar Y$ es la media. El $R^2$ da una medida de la capacidad de ajuste del modelo, es decir que da una noción de cuanta variabilidad de $Y$ queda explicada por el modelo. Cuando el valor se encuentra más cercano a 1 quiere decir que el modelo explica mejor la variabilidad.

A medida que se agregan variables al modelo este valor siempre crece, a pesar de que estas nuevas variable no aporten a la estimación. Por eso es que cuando se quiere comparar dos modelos es preferible usar el coeficiente de determinación ajustado como:

$$
R_{a}^{2}=1-\frac{n-1}{n-p} \frac{\|Y-\hat{Y}\|^{2}}{\|Y-\bar{Y}\|^{2}}=1-\left(1-R^{2}\right) \frac{n}{n-p}
$$

## Punto 7

Si se quiere analizar si la regresión es significativa se puede hacer el siguiente test

$$H_{0}: \beta_{1}=\cdots=\beta_{p-1}=0 \quad \text { Vs. } \quad H_{1}: \text { Algun } \quad \beta_{i} \neq 0, \quad i=1, \ldots, p-1$$

$$
\varphi(\underline{X})= \begin{cases}1 & \text { si } \quad F>\mathcal{F}_{p-1, n-p, 1-\alpha} \\ 0 & \text { en otro caso }\end{cases}
$$

Donde:

$$
F=\frac{(C \hat{\beta})^{T}\left(C\left(\mathbf{X}^{T} \mathbf{X}\right)^{-1} C^{T}\right)^{-1}(C \hat{\beta})}{(p - 1) S^{2}} 
$$

Con:

$$
\mathbf{C}=\left[\begin{array}{ccc}0 & 1 \ldots & 0 \\0 & . & . \\. & . & \cdot \\. & \cdot & \cdot \\0 & \ldots & 1\end{array}\right] ; C\in \mathcal{R}^{(p-1)\times p}
$$

Que representa la manera que está armado el test ($\beta_{1}=0 ; \beta_{2}=0 ...$)

En este caso el p-valor se calcula como:

$$
p-\text { valor }=\mathbf{P}\left(F \geq F_{o b s}\right), \quad F \sim \mathcal{F}_{p - 1, n-p}
$$

Por lo tanto en este caso el p-valor está tan cercano a 0 que significa que la regresión es significativa.

## Punto 8

```{r}

```

## Punto 9

## Punto 10

Para la selección de modelos se consideran todas las posibles combinaciones de variables para poder encontrar el mejor de los modelos. Para considerar cual es el mejor es necesario definir métricas.

Se utilizaran 3 métricas:

-   $$
    R_{a}^{2}=1-\frac{n-1}{n-p} \frac{\|Y-\hat{Y}\|^{2}}{\|Y-\bar{Y}\|^{2}}
    $$

-   $$
    C p=\frac{\left\|Y-\hat{Y}_{p}\right\|^{2}}{S^{2}}+2 p-n, \quad \quad S^{2}=\frac{\left\|Y-\hat{Y}_{k}\right\|^{2}}{n-k}
    $$

-   $$
    \widehat{E C M}=\frac{1}{n} \sum_{i=1}^{n} r_{-i}^{2}=\frac{1}{n} \sum_{i=1}^{n} \frac{r^{2}}{\left(1-p_{i i}\right)^{2}}
    $$

La bondad de ajuste está dada por el $R_{a}^{2}$, mientras que la bondad de predicción está dada por el $C_p$ . Otra métrica también utilizada es el error cuadrático medio para verificar cuanto se aleja la estimación de la medición, para este caso se usó el método de CV para medir esta métrica.

```{r, results=TRUE}
exhaustive = stepwise(data)
Xy<-data.frame(X[,-1],data$BMI)
bestlm <-bestglm(Xy = Xy,
                      IC = "CV",
                      method = "exhaustive")
```

Utilizando la función regsubsets con el metodo exhaustivo se obtuvieron los mejores (se queda con el modelo con mayor F) modelos para la cantidad de variables. En el gráfico de arriba se pueden ver como cambia el $R_{a}^{2}$ y el $C_p$ a medida que cambian la cantidad de variables. De aquí se podría considerar que el óptimo se obtiene con 5 variables, pero no hay mucha diferencia con los menores. Teniendo en cuenta de que se prefiere usar menor cantidad de variables se podría tomar el de 4 o 3.

```{r, results=TRUE}
summary(exhaustive)
```

En esta tabla se puede ver cuales variables se utilizan para la cantidad de variables.

Para calcular el error cuadratico medio en cambio se usa la función bestglm ya que elije el mejor modelo (en este caso se le puede pedir que el mejor sea el que tenga menor ECM) usando cross validation.

```{r, results=TRUE}
bestlm$Subsets
```

Este algoritmo encuentra que el mejor modelo (el que minimiza el ECM) es el de 3 variables.

Comparando los dos resultados elegimos el de 4 variables (en este caso dieron iguales) ya que para el segundo análisis no se encuentra muy alejado del mínimo, y para el primer análisis se encuentra cerca del óptimo.

El modelo entonces resulta con los siguientes estimadores:

```{r}
coef(exhaustive, 4)
```

## Punto 11

## Para el final

Se considera que solo las columnas de Glucosa, Presión Sanguínea, Insulina y la Edad no pueden ser 0.

```{r, results = TRUE}
missing_data = count_missing_values(data, c('Glucose', 'BloodPressure', 'Insulin', 'Age'), 0, equals)
missing_data * 100 / nrow(data)
```

Por otro lado se enti

```{r, results = TRUE}
missing_data = count_missing_values(data, c('DiabetesPedigreeFunction'), 1, greater_than)
missing_data * 100 / nrow(data)
```

edad

```{r, results = TRUE}
missing_data = count_missing_values(data, c('Age'), 21, less_than)
missing_data * 100 / nrow(data)
```

Se muestran el porcentaje de valores nulos de cada columna. Para Glucosa y Presión Sanguínea no representa una porción grande de los datos por lo que podríamos quitar esas líneas, pero para la Insulina en cambio si. En los siguientes probaremos formas de tratar estos datos:

-   Eliminar esas filas como hicimos con las otras columnas.

-   Asignarles valores en función de alguna métrica como por ejemplo la media.

Para el caso de DiabetesPedigreeFunction también decidimos quitarlos.

```{r}
clean_data = adjust_data(data, "Glucose", equals, 0)
clean_data = adjust_data(clean_data, "BloodPressure", equals, 0)
clean_data = adjust_data(clean_data, "DiabetesPedigreeFunction", greater_than, 1)
```

## 
